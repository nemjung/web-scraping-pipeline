This project is designed as a hands-on learning experience in Data Engineering, demonstrating the construction of a basic ETL (Extract, Transform, Load) pipeline. It aims to provide practical understanding and skill development in core Data Engineering concepts and technologies.

The pipeline encompasses the following stages:

* **Web Scraping:** Utilizing Python and libraries like Beautiful Soup and Requests to extract data from target websites.
* **Data Transformation:** Employing Python to clean, transform, and prepare the extracted data for loading.
* **Data Loading:** Loading the processed data into a MySQL relational database, leveraging SQLAlchemy for efficient database interaction.
* **Containerization:** Implementing Docker and Docker Compose to containerize the application and database, ensuring a consistent and reproducible environment.

Technologies employed in this project include:

* Python (Beautiful Soup, Requests, MySQL Connector, SQLAlchemy)
* MySQL
* Docker & Docker Compose

This project serves as an educational tool, providing a practical foundation in data pipeline development and key Data Engineering practices.
